{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential , Model\n",
    "from keras.layers import MaxPooling2D , Conv2D , Dense , Activation , Dropout , Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "      <th>locations</th>\n",
       "      <th>scene_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[206, 195, 187, 183, 177, 175, 174, 193, 198, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-118.40497658522878, 33.940618514147936]</td>\n",
       "      <td>20170620_175442_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[215, 209, 200, 196, 192, 197, 205, 168, 155, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.392469714, 37.6176425378]</td>\n",
       "      <td>20161212_180859_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[204, 214, 220, 219, 213, 205, 198, 193, 199, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.397578597, 37.6209247852]</td>\n",
       "      <td>20170524_181349_0e2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[179, 174, 179, 178, 173, 170, 168, 168, 168, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.214849831, 37.7203378331]</td>\n",
       "      <td>20161110_180707_0e1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[222, 222, 218, 214, 208, 205, 207, 206, 206, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-117.862173435, 33.6796854072]</td>\n",
       "      <td>20160813_184932_0c64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31995</td>\n",
       "      <td>[217, 197, 206, 221, 219, 200, 202, 222, 231, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-117.51619965614212, 34.08254781774721]</td>\n",
       "      <td>20170726_174731_0f34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31996</td>\n",
       "      <td>[184, 198, 218, 222, 220, 216, 216, 215, 210, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-117.2352626288379, 32.79485122236176]</td>\n",
       "      <td>20160726_173906_0e0e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31997</td>\n",
       "      <td>[121, 121, 119, 117, 119, 112, 118, 117, 126, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-121.4835244137727, 38.53386512064711]</td>\n",
       "      <td>20151030_162249_0c03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31998</td>\n",
       "      <td>[172, 190, 202, 202, 196, 193, 188, 191, 199, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-118.32580026781089, 33.83093529544055]</td>\n",
       "      <td>20160715_174337_0e0e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31999</td>\n",
       "      <td>[161, 172, 189, 190, 178, 151, 156, 171, 174, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-122.3275363089765, 37.57495862200392]</td>\n",
       "      <td>20170712_181006_0f12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  labels  \\\n",
       "0      [206, 195, 187, 183, 177, 175, 174, 193, 198, ...       1   \n",
       "1      [215, 209, 200, 196, 192, 197, 205, 168, 155, ...       1   \n",
       "2      [204, 214, 220, 219, 213, 205, 198, 193, 199, ...       1   \n",
       "3      [179, 174, 179, 178, 173, 170, 168, 168, 168, ...       1   \n",
       "4      [222, 222, 218, 214, 208, 205, 207, 206, 206, ...       1   \n",
       "...                                                  ...     ...   \n",
       "31995  [217, 197, 206, 221, 219, 200, 202, 222, 231, ...       0   \n",
       "31996  [184, 198, 218, 222, 220, 216, 216, 215, 210, ...       0   \n",
       "31997  [121, 121, 119, 117, 119, 112, 118, 117, 126, ...       0   \n",
       "31998  [172, 190, 202, 202, 196, 193, 188, 191, 199, ...       0   \n",
       "31999  [161, 172, 189, 190, 178, 151, 156, 171, 174, ...       0   \n",
       "\n",
       "                                       locations             scene_ids  \n",
       "0      [-118.40497658522878, 33.940618514147936]  20170620_175442_0e30  \n",
       "1                [-122.392469714, 37.6176425378]  20161212_180859_0e30  \n",
       "2                [-122.397578597, 37.6209247852]  20170524_181349_0e2f  \n",
       "3                [-122.214849831, 37.7203378331]  20161110_180707_0e1f  \n",
       "4                [-117.862173435, 33.6796854072]  20160813_184932_0c64  \n",
       "...                                          ...                   ...  \n",
       "31995   [-117.51619965614212, 34.08254781774721]  20170726_174731_0f34  \n",
       "31996    [-117.2352626288379, 32.79485122236176]  20160726_173906_0e0e  \n",
       "31997    [-121.4835244137727, 38.53386512064711]  20151030_162249_0c03  \n",
       "31998   [-118.32580026781089, 33.83093529544055]  20160715_174337_0e0e  \n",
       "31999    [-122.3275363089765, 37.57495862200392]  20170712_181006_0f12  \n",
       "\n",
       "[32000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('G:/Software/Machine learning/Datasets/Planet json/planesnet.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>labels</th>\n",
       "      <th>locations</th>\n",
       "      <th>scene_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[206, 195, 187, 183, 177, 175, 174, 193, 198, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-118.40497658522878, 33.940618514147936]</td>\n",
       "      <td>20170620_175442_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[215, 209, 200, 196, 192, 197, 205, 168, 155, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.392469714, 37.6176425378]</td>\n",
       "      <td>20161212_180859_0e30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[204, 214, 220, 219, 213, 205, 198, 193, 199, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.397578597, 37.6209247852]</td>\n",
       "      <td>20170524_181349_0e2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[179, 174, 179, 178, 173, 170, 168, 168, 168, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-122.214849831, 37.7203378331]</td>\n",
       "      <td>20161110_180707_0e1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[222, 222, 218, 214, 208, 205, 207, 206, 206, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-117.862173435, 33.6796854072]</td>\n",
       "      <td>20160813_184932_0c64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  labels  \\\n",
       "0  [206, 195, 187, 183, 177, 175, 174, 193, 198, ...       1   \n",
       "1  [215, 209, 200, 196, 192, 197, 205, 168, 155, ...       1   \n",
       "2  [204, 214, 220, 219, 213, 205, 198, 193, 199, ...       1   \n",
       "3  [179, 174, 179, 178, 173, 170, 168, 168, 168, ...       1   \n",
       "4  [222, 222, 218, 214, 208, 205, 207, 206, 206, ...       1   \n",
       "\n",
       "                                   locations             scene_ids  \n",
       "0  [-118.40497658522878, 33.940618514147936]  20170620_175442_0e30  \n",
       "1            [-122.392469714, 37.6176425378]  20161212_180859_0e30  \n",
       "2            [-122.397578597, 37.6209247852]  20170524_181349_0e2f  \n",
       "3            [-122.214849831, 37.7203378331]  20161110_180707_0e1f  \n",
       "4            [-117.862173435, 33.6796854072]  20160813_184932_0c64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data         0\n",
       "labels       0\n",
       "locations    0\n",
       "scene_ids    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-118.40497658522878, 33.940618514147936]\n",
       "1                  [-122.392469714, 37.6176425378]\n",
       "2                  [-122.397578597, 37.6209247852]\n",
       "3                  [-122.214849831, 37.7203378331]\n",
       "4                  [-117.862173435, 33.6796854072]\n",
       "                           ...                    \n",
       "31995     [-117.51619965614212, 34.08254781774721]\n",
       "31996      [-117.2352626288379, 32.79485122236176]\n",
       "31997      [-121.4835244137727, 38.53386512064711]\n",
       "31998     [-118.32580026781089, 33.83093529544055]\n",
       "31999      [-122.3275363089765, 37.57495862200392]\n",
       "Name: locations, Length: 32000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['locations']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 20, 20, 3)\n",
      "(32000,)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for d in data['data']:\n",
    "    d = np.array(d)\n",
    "    x.append(d.reshape((3 , 20 , 20)).T.reshape((20 , 20 , 3)))\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(data['labels'])\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x , y , test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[137, 135, 138],\n",
       "         [143, 141, 143],\n",
       "         [114, 119, 120],\n",
       "         ...,\n",
       "         [140, 129, 114],\n",
       "         [188, 173, 147],\n",
       "         [232, 213, 190]],\n",
       "\n",
       "        [[ 93,  94,  93],\n",
       "         [114, 114, 116],\n",
       "         [119, 122, 126],\n",
       "         ...,\n",
       "         [132, 124, 120],\n",
       "         [157, 148, 134],\n",
       "         [178, 165, 150]],\n",
       "\n",
       "        [[104, 108, 105],\n",
       "         [113, 115, 115],\n",
       "         [121, 124, 129],\n",
       "         ...,\n",
       "         [141, 132, 131],\n",
       "         [147, 140, 143],\n",
       "         [100,  98,  95]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 80,  87,  87],\n",
       "         [ 98, 107, 111],\n",
       "         [ 92,  96,  99],\n",
       "         ...,\n",
       "         [214, 212, 207],\n",
       "         [198, 198, 194],\n",
       "         [173, 171, 166]],\n",
       "\n",
       "        [[117, 121, 118],\n",
       "         [110, 111, 111],\n",
       "         [ 97,  99, 104],\n",
       "         ...,\n",
       "         [232, 232, 229],\n",
       "         [227, 227, 226],\n",
       "         [204, 206, 203]],\n",
       "\n",
       "        [[170, 172, 167],\n",
       "         [150, 147, 145],\n",
       "         [121, 118, 121],\n",
       "         ...,\n",
       "         [195, 199, 197],\n",
       "         [232, 232, 229],\n",
       "         [206, 211, 208]]],\n",
       "\n",
       "\n",
       "       [[[238, 217, 200],\n",
       "         [237, 216, 198],\n",
       "         [237, 216, 198],\n",
       "         ...,\n",
       "         [234, 217, 199],\n",
       "         [235, 218, 200],\n",
       "         [234, 216, 197]],\n",
       "\n",
       "        [[237, 217, 198],\n",
       "         [239, 218, 200],\n",
       "         [240, 220, 201],\n",
       "         ...,\n",
       "         [234, 216, 198],\n",
       "         [235, 217, 199],\n",
       "         [233, 215, 197]],\n",
       "\n",
       "        [[238, 218, 199],\n",
       "         [236, 217, 197],\n",
       "         [241, 221, 201],\n",
       "         ...,\n",
       "         [233, 215, 196],\n",
       "         [234, 215, 196],\n",
       "         [234, 215, 197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[237, 217, 198],\n",
       "         [237, 218, 199],\n",
       "         [235, 217, 196],\n",
       "         ...,\n",
       "         [240, 219, 198],\n",
       "         [240, 219, 199],\n",
       "         [242, 220, 201]],\n",
       "\n",
       "        [[242, 221, 203],\n",
       "         [240, 221, 202],\n",
       "         [237, 218, 198],\n",
       "         ...,\n",
       "         [242, 221, 201],\n",
       "         [241, 220, 200],\n",
       "         [241, 219, 199]],\n",
       "\n",
       "        [[242, 222, 203],\n",
       "         [240, 220, 201],\n",
       "         [238, 218, 199],\n",
       "         ...,\n",
       "         [241, 220, 200],\n",
       "         [237, 216, 195],\n",
       "         [235, 214, 192]]],\n",
       "\n",
       "\n",
       "       [[[185, 183, 177],\n",
       "         [189, 188, 179],\n",
       "         [189, 187, 181],\n",
       "         ...,\n",
       "         [189, 184, 175],\n",
       "         [187, 182, 173],\n",
       "         [176, 172, 163]],\n",
       "\n",
       "        [[181, 179, 172],\n",
       "         [181, 180, 172],\n",
       "         [182, 180, 171],\n",
       "         ...,\n",
       "         [192, 189, 179],\n",
       "         [189, 186, 176],\n",
       "         [185, 181, 173]],\n",
       "\n",
       "        [[178, 175, 168],\n",
       "         [175, 173, 166],\n",
       "         [178, 175, 166],\n",
       "         ...,\n",
       "         [187, 185, 175],\n",
       "         [182, 181, 170],\n",
       "         [184, 181, 171]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[194, 188, 176],\n",
       "         [184, 179, 166],\n",
       "         [202, 195, 180],\n",
       "         ...,\n",
       "         [201, 197, 189],\n",
       "         [207, 203, 195],\n",
       "         [213, 208, 200]],\n",
       "\n",
       "        [[236, 225, 211],\n",
       "         [230, 220, 205],\n",
       "         [229, 220, 206],\n",
       "         ...,\n",
       "         [200, 194, 186],\n",
       "         [199, 194, 185],\n",
       "         [204, 199, 188]],\n",
       "\n",
       "        [[245, 234, 218],\n",
       "         [239, 227, 214],\n",
       "         [235, 225, 212],\n",
       "         ...,\n",
       "         [186, 180, 169],\n",
       "         [191, 184, 174],\n",
       "         [179, 176, 165]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[193, 186, 172],\n",
       "         [191, 183, 171],\n",
       "         [185, 178, 166],\n",
       "         ...,\n",
       "         [198, 192, 178],\n",
       "         [194, 188, 174],\n",
       "         [190, 183, 170]],\n",
       "\n",
       "        [[197, 191, 176],\n",
       "         [194, 188, 174],\n",
       "         [187, 181, 169],\n",
       "         ...,\n",
       "         [198, 192, 177],\n",
       "         [189, 183, 170],\n",
       "         [183, 178, 164]],\n",
       "\n",
       "        [[201, 195, 179],\n",
       "         [203, 196, 181],\n",
       "         [196, 189, 176],\n",
       "         ...,\n",
       "         [193, 188, 174],\n",
       "         [192, 187, 173],\n",
       "         [194, 188, 174]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[184, 177, 165],\n",
       "         [185, 179, 166],\n",
       "         [182, 176, 164],\n",
       "         ...,\n",
       "         [171, 164, 151],\n",
       "         [177, 170, 156],\n",
       "         [184, 177, 163]],\n",
       "\n",
       "        [[191, 185, 171],\n",
       "         [188, 182, 169],\n",
       "         [182, 177, 164],\n",
       "         ...,\n",
       "         [170, 164, 151],\n",
       "         [174, 167, 154],\n",
       "         [181, 174, 161]],\n",
       "\n",
       "        [[195, 189, 174],\n",
       "         [184, 179, 166],\n",
       "         [178, 174, 162],\n",
       "         ...,\n",
       "         [171, 165, 153],\n",
       "         [174, 167, 154],\n",
       "         [179, 172, 159]]],\n",
       "\n",
       "\n",
       "       [[[236, 223, 205],\n",
       "         [236, 221, 204],\n",
       "         [232, 218, 200],\n",
       "         ...,\n",
       "         [156, 144, 127],\n",
       "         [163, 149, 130],\n",
       "         [155, 142, 122]],\n",
       "\n",
       "        [[235, 221, 204],\n",
       "         [237, 223, 205],\n",
       "         [235, 220, 203],\n",
       "         ...,\n",
       "         [178, 162, 143],\n",
       "         [172, 157, 138],\n",
       "         [164, 150, 129]],\n",
       "\n",
       "        [[233, 219, 202],\n",
       "         [239, 224, 205],\n",
       "         [238, 222, 205],\n",
       "         ...,\n",
       "         [181, 165, 145],\n",
       "         [173, 158, 138],\n",
       "         [166, 152, 129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[231, 215, 194],\n",
       "         [234, 218, 199],\n",
       "         [228, 214, 194],\n",
       "         ...,\n",
       "         [181, 164, 142],\n",
       "         [171, 154, 132],\n",
       "         [165, 148, 124]],\n",
       "\n",
       "        [[215, 201, 182],\n",
       "         [224, 210, 192],\n",
       "         [226, 213, 195],\n",
       "         ...,\n",
       "         [182, 164, 142],\n",
       "         [169, 151, 129],\n",
       "         [168, 149, 128]],\n",
       "\n",
       "        [[232, 218, 201],\n",
       "         [246, 232, 219],\n",
       "         [239, 225, 212],\n",
       "         ...,\n",
       "         [173, 157, 137],\n",
       "         [162, 146, 124],\n",
       "         [157, 141, 120]]],\n",
       "\n",
       "\n",
       "       [[[231, 228, 220],\n",
       "         [221, 218, 206],\n",
       "         [204, 202, 190],\n",
       "         ...,\n",
       "         [162, 157, 147],\n",
       "         [168, 163, 150],\n",
       "         [183, 178, 165]],\n",
       "\n",
       "        [[231, 228, 220],\n",
       "         [221, 219, 207],\n",
       "         [199, 197, 185],\n",
       "         ...,\n",
       "         [166, 160, 146],\n",
       "         [164, 160, 145],\n",
       "         [176, 170, 158]],\n",
       "\n",
       "        [[209, 208, 199],\n",
       "         [206, 206, 194],\n",
       "         [188, 187, 175],\n",
       "         ...,\n",
       "         [176, 171, 158],\n",
       "         [174, 169, 157],\n",
       "         [177, 172, 159]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[182, 179, 167],\n",
       "         [176, 171, 159],\n",
       "         [178, 171, 159],\n",
       "         ...,\n",
       "         [182, 176, 168],\n",
       "         [178, 171, 160],\n",
       "         [182, 176, 164]],\n",
       "\n",
       "        [[187, 184, 170],\n",
       "         [179, 174, 158],\n",
       "         [180, 175, 157],\n",
       "         ...,\n",
       "         [209, 201, 195],\n",
       "         [197, 190, 180],\n",
       "         [188, 180, 168]],\n",
       "\n",
       "        [[196, 192, 180],\n",
       "         [190, 187, 174],\n",
       "         [186, 184, 171],\n",
       "         ...,\n",
       "         [213, 205, 198],\n",
       "         [211, 203, 194],\n",
       "         [205, 197, 186]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = MinMaxScaler()\n",
    "scalar.fit(x_train.reshape(x_train.shape[0] , -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scalar.transform(x_train.reshape(x_train.shape[0], -1)).reshape(x_train.shape)\n",
    "x_test = scalar.transform(x_test.reshape(x_test.shape[0], -1)).reshape(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.52988048, 0.50617284, 0.53012048],\n",
       "         [0.552     , 0.54216867, 0.55378486],\n",
       "         [0.44047619, 0.44715447, 0.46428571],\n",
       "         ...,\n",
       "         [0.54183267, 0.48571429, 0.436     ],\n",
       "         [0.73306773, 0.66393443, 0.56626506],\n",
       "         [0.90944882, 0.83464567, 0.74409449]],\n",
       "\n",
       "        [[0.35458167, 0.356     , 0.35458167],\n",
       "         [0.43824701, 0.43824701, 0.44621514],\n",
       "         [0.45816733, 0.46586345, 0.484     ],\n",
       "         ...,\n",
       "         [0.508     , 0.45867769, 0.46      ],\n",
       "         [0.61111111, 0.572     , 0.51984127],\n",
       "         [0.69444444, 0.64285714, 0.58498024]],\n",
       "\n",
       "        [[0.39840637, 0.4       , 0.40239044],\n",
       "         [0.432     , 0.41908714, 0.43548387],\n",
       "         [0.46613546, 0.46311475, 0.48987854],\n",
       "         ...,\n",
       "         [0.54581673, 0.49795918, 0.5       ],\n",
       "         [0.56626506, 0.51882845, 0.54098361],\n",
       "         [0.38492063, 0.35655738, 0.35483871]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.30278884, 0.30864198, 0.31983806],\n",
       "         [0.37698413, 0.39344262, 0.42168675],\n",
       "         [0.348     , 0.364     , 0.38095238],\n",
       "         ...,\n",
       "         [0.83665339, 0.82304527, 0.80408163],\n",
       "         [0.772     , 0.76639344, 0.75403226],\n",
       "         [0.67330677, 0.65      , 0.63821138]],\n",
       "\n",
       "        [[0.45238095, 0.46825397, 0.46062992],\n",
       "         [0.42460317, 0.40740741, 0.424     ],\n",
       "         [0.368     , 0.3526971 , 0.39840637],\n",
       "         ...,\n",
       "         [0.90836653, 0.90456432, 0.89430894],\n",
       "         [0.88976378, 0.88617886, 0.884     ],\n",
       "         [0.79841897, 0.804     , 0.79365079]],\n",
       "\n",
       "        [[0.66269841, 0.66122449, 0.64516129],\n",
       "         [0.58      , 0.55186722, 0.56175299],\n",
       "         [0.46613546, 0.41452991, 0.45967742],\n",
       "         ...,\n",
       "         [0.76190476, 0.77142857, 0.768     ],\n",
       "         [0.90836653, 0.90456432, 0.89473684],\n",
       "         [0.80478088, 0.81742739, 0.812     ]]],\n",
       "\n",
       "\n",
       "       [[[0.93227092, 0.8436214 , 0.77911647],\n",
       "         [0.928     , 0.84337349, 0.77290837],\n",
       "         [0.92857143, 0.84146341, 0.77380952],\n",
       "         ...,\n",
       "         [0.91633466, 0.84489796, 0.776     ],\n",
       "         [0.92031873, 0.84836066, 0.77911647],\n",
       "         [0.91732283, 0.84645669, 0.77165354]],\n",
       "\n",
       "        [[0.92828685, 0.848     , 0.77290837],\n",
       "         [0.93625498, 0.85258964, 0.78087649],\n",
       "         [0.94023904, 0.85943775, 0.784     ],\n",
       "         ...,\n",
       "         [0.916     , 0.83884298, 0.772     ],\n",
       "         [0.92063492, 0.848     , 0.77777778],\n",
       "         [0.91269841, 0.84126984, 0.77075099]],\n",
       "\n",
       "        [[0.93227092, 0.84897959, 0.77689243],\n",
       "         [0.924     , 0.84232365, 0.76612903],\n",
       "         [0.94422311, 0.86065574, 0.78137652],\n",
       "         ...,\n",
       "         [0.9123506 , 0.83673469, 0.76209677],\n",
       "         [0.91566265, 0.83263598, 0.75819672],\n",
       "         [0.91666667, 0.83606557, 0.76612903]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.92828685, 0.8436214 , 0.76923077],\n",
       "         [0.92857143, 0.84836066, 0.7751004 ],\n",
       "         [0.92      , 0.848     , 0.76587302],\n",
       "         ...,\n",
       "         [0.94023904, 0.85185185, 0.76734694],\n",
       "         [0.94      , 0.85245902, 0.77419355],\n",
       "         [0.94820717, 0.85416667, 0.7804878 ]],\n",
       "\n",
       "        [[0.9484127 , 0.86507937, 0.79527559],\n",
       "         [0.94047619, 0.8600823 , 0.788     ],\n",
       "         [0.928     , 0.84647303, 0.77290837],\n",
       "         ...,\n",
       "         [0.94820717, 0.85892116, 0.7804878 ],\n",
       "         [0.94488189, 0.85772358, 0.78      ],\n",
       "         [0.94466403, 0.856     , 0.77777778]],\n",
       "\n",
       "        [[0.9484127 , 0.86530612, 0.79032258],\n",
       "         [0.94      , 0.85477178, 0.78486056],\n",
       "         [0.93227092, 0.84188034, 0.77419355],\n",
       "         ...,\n",
       "         [0.94444444, 0.85714286, 0.78      ],\n",
       "         [0.92828685, 0.83817427, 0.75708502],\n",
       "         [0.92031873, 0.82987552, 0.748     ]]],\n",
       "\n",
       "\n",
       "       [[[0.72111554, 0.7037037 , 0.68674699],\n",
       "         [0.736     , 0.73092369, 0.69721116],\n",
       "         [0.73809524, 0.72357724, 0.70634921],\n",
       "         ...,\n",
       "         [0.73705179, 0.71020408, 0.68      ],\n",
       "         [0.72908367, 0.70081967, 0.67068273],\n",
       "         [0.68897638, 0.67322835, 0.63779528]],\n",
       "\n",
       "        [[0.70517928, 0.696     , 0.66932271],\n",
       "         [0.70517928, 0.70119522, 0.66932271],\n",
       "         [0.70916335, 0.69879518, 0.664     ],\n",
       "         ...,\n",
       "         [0.748     , 0.72727273, 0.696     ],\n",
       "         [0.73809524, 0.724     , 0.68650794],\n",
       "         [0.72222222, 0.70634921, 0.67588933]],\n",
       "\n",
       "        [[0.69322709, 0.67346939, 0.65338645],\n",
       "         [0.68      , 0.65975104, 0.64112903],\n",
       "         [0.69322709, 0.67213115, 0.63967611],\n",
       "         ...,\n",
       "         [0.72908367, 0.71428571, 0.67741935],\n",
       "         [0.70682731, 0.69037657, 0.65163934],\n",
       "         [0.71825397, 0.69672131, 0.66129032]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.75697211, 0.72427984, 0.68016194],\n",
       "         [0.71825397, 0.68852459, 0.64257028],\n",
       "         [0.788     , 0.76      , 0.70238095],\n",
       "         ...,\n",
       "         [0.78486056, 0.76131687, 0.73061224],\n",
       "         [0.808     , 0.78688525, 0.75806452],\n",
       "         [0.83266932, 0.80416667, 0.77642276]],\n",
       "\n",
       "        [[0.92460317, 0.88095238, 0.82677165],\n",
       "         [0.90079365, 0.85596708, 0.8       ],\n",
       "         [0.896     , 0.85477178, 0.80478088],\n",
       "         ...,\n",
       "         [0.78087649, 0.74688797, 0.7195122 ],\n",
       "         [0.77952756, 0.75203252, 0.72      ],\n",
       "         [0.79841897, 0.776     , 0.73412698]],\n",
       "\n",
       "        [[0.96031746, 0.91428571, 0.85080645],\n",
       "         [0.936     , 0.88381743, 0.83665339],\n",
       "         [0.92031873, 0.87179487, 0.8266129 ],\n",
       "         ...,\n",
       "         [0.72619048, 0.69387755, 0.656     ],\n",
       "         [0.74501992, 0.70539419, 0.67206478],\n",
       "         [0.69721116, 0.67219917, 0.64      ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.75298805, 0.71604938, 0.66666667],\n",
       "         [0.744     , 0.71084337, 0.66533865],\n",
       "         [0.72222222, 0.68699187, 0.6468254 ],\n",
       "         ...,\n",
       "         [0.77290837, 0.74285714, 0.692     ],\n",
       "         [0.75697211, 0.72540984, 0.6746988 ],\n",
       "         [0.74409449, 0.71653543, 0.66535433]],\n",
       "\n",
       "        [[0.7689243 , 0.744     , 0.68525896],\n",
       "         [0.75697211, 0.73306773, 0.67729084],\n",
       "         [0.72908367, 0.70281124, 0.656     ],\n",
       "         ...,\n",
       "         [0.772     , 0.73966942, 0.688     ],\n",
       "         [0.73809524, 0.712     , 0.66269841],\n",
       "         [0.71428571, 0.69444444, 0.64031621]],\n",
       "\n",
       "        [[0.78486056, 0.75510204, 0.69721116],\n",
       "         [0.792     , 0.75518672, 0.7016129 ],\n",
       "         [0.76494024, 0.7295082 , 0.68016194],\n",
       "         ...,\n",
       "         [0.75298805, 0.72653061, 0.6733871 ],\n",
       "         [0.74698795, 0.71548117, 0.66393443],\n",
       "         [0.75793651, 0.72540984, 0.6733871 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.71713147, 0.67901235, 0.63562753],\n",
       "         [0.72222222, 0.68852459, 0.64257028],\n",
       "         [0.708     , 0.684     , 0.63888889],\n",
       "         ...,\n",
       "         [0.66533865, 0.6255144 , 0.5755102 ],\n",
       "         [0.688     , 0.65163934, 0.60080645],\n",
       "         [0.71713147, 0.675     , 0.62601626]],\n",
       "\n",
       "        [[0.74603175, 0.72222222, 0.66929134],\n",
       "         [0.73412698, 0.69958848, 0.656     ],\n",
       "         [0.708     , 0.67634855, 0.6374502 ],\n",
       "         ...,\n",
       "         [0.66135458, 0.62240664, 0.57723577],\n",
       "         [0.68110236, 0.64227642, 0.596     ],\n",
       "         [0.70750988, 0.676     , 0.62698413]],\n",
       "\n",
       "        [[0.76190476, 0.73061224, 0.6733871 ],\n",
       "         [0.716     , 0.6846473 , 0.64541833],\n",
       "         [0.69322709, 0.65384615, 0.625     ],\n",
       "         ...,\n",
       "         [0.66666667, 0.63265306, 0.592     ],\n",
       "         [0.67729084, 0.63485477, 0.59109312],\n",
       "         [0.69721116, 0.65560166, 0.616     ]]],\n",
       "\n",
       "\n",
       "       [[[0.92430279, 0.86831276, 0.79919679],\n",
       "         [0.924     , 0.86345382, 0.79681275],\n",
       "         [0.90873016, 0.8495935 , 0.78174603],\n",
       "         ...,\n",
       "         [0.60557769, 0.54693878, 0.488     ],\n",
       "         [0.63346614, 0.56557377, 0.49799197],\n",
       "         [0.60629921, 0.55511811, 0.47637795]],\n",
       "\n",
       "        [[0.92031873, 0.864     , 0.79681275],\n",
       "         [0.92828685, 0.87250996, 0.80079681],\n",
       "         [0.92031873, 0.85943775, 0.792     ],\n",
       "         ...,\n",
       "         [0.692     , 0.61570248, 0.552     ],\n",
       "         [0.67063492, 0.608     , 0.53571429],\n",
       "         [0.63888889, 0.58333333, 0.50197628]],\n",
       "\n",
       "        [[0.9123506 , 0.85306122, 0.78884462],\n",
       "         [0.936     , 0.87136929, 0.7983871 ],\n",
       "         [0.93227092, 0.8647541 , 0.79757085],\n",
       "         ...,\n",
       "         [0.70517928, 0.63265306, 0.55645161],\n",
       "         [0.67068273, 0.59414226, 0.5204918 ],\n",
       "         [0.6468254 , 0.57786885, 0.49193548]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.90438247, 0.83539095, 0.75303644],\n",
       "         [0.91666667, 0.84836066, 0.7751004 ],\n",
       "         [0.892     , 0.836     , 0.75793651],\n",
       "         ...,\n",
       "         [0.70517928, 0.6255144 , 0.53877551],\n",
       "         [0.664     , 0.58606557, 0.50403226],\n",
       "         [0.64143426, 0.55416667, 0.46747967]],\n",
       "\n",
       "        [[0.84126984, 0.78571429, 0.71259843],\n",
       "         [0.87698413, 0.81481481, 0.748     ],\n",
       "         [0.884     , 0.82572614, 0.76095618],\n",
       "         ...,\n",
       "         [0.70916335, 0.62240664, 0.54065041],\n",
       "         [0.66141732, 0.57723577, 0.496     ],\n",
       "         [0.65612648, 0.576     , 0.49603175]],\n",
       "\n",
       "        [[0.90873016, 0.84897959, 0.78225806],\n",
       "         [0.964     , 0.90456432, 0.85657371],\n",
       "         [0.93625498, 0.87179487, 0.8266129 ],\n",
       "         ...,\n",
       "         [0.67460317, 0.6       , 0.528     ],\n",
       "         [0.62948207, 0.54771784, 0.46963563],\n",
       "         [0.60956175, 0.52697095, 0.46      ]]],\n",
       "\n",
       "\n",
       "       [[[0.90438247, 0.88888889, 0.85943775],\n",
       "         [0.864     , 0.85140562, 0.80478088],\n",
       "         [0.79761905, 0.78455285, 0.74206349],\n",
       "         ...,\n",
       "         [0.62948207, 0.6       , 0.568     ],\n",
       "         [0.65338645, 0.62295082, 0.57831325],\n",
       "         [0.71653543, 0.69685039, 0.64566929]],\n",
       "\n",
       "        [[0.90438247, 0.892     , 0.86055777],\n",
       "         [0.86454183, 0.85657371, 0.80876494],\n",
       "         [0.77689243, 0.76706827, 0.72      ],\n",
       "         ...,\n",
       "         [0.644     , 0.60743802, 0.564     ],\n",
       "         [0.63888889, 0.62      , 0.56349206],\n",
       "         [0.68650794, 0.66269841, 0.61660079]],\n",
       "\n",
       "        [[0.81673307, 0.80816327, 0.77689243],\n",
       "         [0.804     , 0.7966805 , 0.75403226],\n",
       "         [0.73306773, 0.72131148, 0.67611336],\n",
       "         ...,\n",
       "         [0.68525896, 0.65714286, 0.60887097],\n",
       "         [0.6746988 , 0.64016736, 0.59836066],\n",
       "         [0.69047619, 0.65983607, 0.61290323]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.70916335, 0.6872428 , 0.6437247 ],\n",
       "         [0.68650794, 0.6557377 , 0.61445783],\n",
       "         [0.692     , 0.664     , 0.61904762],\n",
       "         ...,\n",
       "         [0.70916335, 0.67489712, 0.64489796],\n",
       "         [0.692     , 0.6557377 , 0.61693548],\n",
       "         [0.70916335, 0.67083333, 0.6300813 ]],\n",
       "\n",
       "        [[0.73015873, 0.71825397, 0.66535433],\n",
       "         [0.6984127 , 0.66666667, 0.612     ],\n",
       "         [0.7       , 0.66804979, 0.60956175],\n",
       "         ...,\n",
       "         [0.81673307, 0.77593361, 0.75609756],\n",
       "         [0.77165354, 0.73577236, 0.7       ],\n",
       "         [0.73517787, 0.7       , 0.6547619 ]],\n",
       "\n",
       "        [[0.76587302, 0.74285714, 0.69758065],\n",
       "         [0.74      , 0.71784232, 0.67729084],\n",
       "         [0.7250996 , 0.6965812 , 0.66129032],\n",
       "         ...,\n",
       "         [0.83333333, 0.79591837, 0.772     ],\n",
       "         [0.8247012 , 0.78423237, 0.75303644],\n",
       "         [0.80079681, 0.7593361 , 0.724     ]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn(data_shape):\n",
    "    \n",
    "    kernel_size = 3\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16 , (kernel_size) , strides = (1 , 1) , padding = 'valid' , input_shape = (data_shape[1] , data_shape[2] , data_shape[3])))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32 , (kernel_size) , strides = (1 , 1) , padding = 'valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "    model.add(Conv2D(64, (kernel_size), strides=(1,1), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 18, 18, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 18, 18, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 18, 18, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 98,657\n",
      "Trainable params: 98,177\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_cnn(x_train.shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    \n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr = 0.0001)\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer = opt , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 8000 samples\n",
      "Epoch 1/15\n",
      " - 36s - loss: 0.1385 - accuracy: 0.9481 - val_loss: 0.1122 - val_accuracy: 0.9603\n",
      "Epoch 2/15\n",
      " - 36s - loss: 0.1145 - accuracy: 0.9579 - val_loss: 0.0986 - val_accuracy: 0.9649\n",
      "Epoch 3/15\n",
      " - 36s - loss: 0.0975 - accuracy: 0.9631 - val_loss: 0.0851 - val_accuracy: 0.9684\n",
      "Epoch 4/15\n",
      " - 36s - loss: 0.0888 - accuracy: 0.9671 - val_loss: 0.0750 - val_accuracy: 0.9735\n",
      "Epoch 5/15\n",
      " - 36s - loss: 0.0777 - accuracy: 0.9701 - val_loss: 0.1777 - val_accuracy: 0.9334\n",
      "Epoch 6/15\n",
      " - 36s - loss: 0.0716 - accuracy: 0.9737 - val_loss: 0.0644 - val_accuracy: 0.9778\n",
      "Epoch 7/15\n",
      " - 36s - loss: 0.0646 - accuracy: 0.9768 - val_loss: 0.0651 - val_accuracy: 0.9778\n",
      "Epoch 8/15\n",
      " - 36s - loss: 0.0618 - accuracy: 0.9772 - val_loss: 0.0630 - val_accuracy: 0.9774\n",
      "Epoch 9/15\n",
      " - 36s - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.0587 - val_accuracy: 0.9795\n",
      "Epoch 10/15\n",
      " - 36s - loss: 0.0470 - accuracy: 0.9837 - val_loss: 0.0622 - val_accuracy: 0.9790\n",
      "Epoch 11/15\n",
      " - 36s - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.0511 - val_accuracy: 0.9825\n",
      "Epoch 12/15\n",
      " - 36s - loss: 0.0419 - accuracy: 0.9850 - val_loss: 0.0503 - val_accuracy: 0.9819\n",
      "Epoch 13/15\n",
      " - 36s - loss: 0.0402 - accuracy: 0.9857 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
      "Epoch 14/15\n",
      " - 36s - loss: 0.0378 - accuracy: 0.9873 - val_loss: 0.0537 - val_accuracy: 0.9833\n",
      "Epoch 15/15\n",
      " - 36s - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0530 - val_accuracy: 0.9830\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train , y_train , batch_size = 64 , epochs = 15 , shuffle = True , verbose = 2 ,\n",
    "                                validation_data = (x_test , y_test), callbacks = [lrate],\n",
    "                               ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
