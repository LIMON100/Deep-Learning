{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.loadtxt('G:/Software/Deep Learning/1/Deep Learning with TensorFlow 2.0 [2019]/13. Business case/Audiobooks_data.csv' , delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscaled_input = df[:,1:-1] \n",
    "target = df[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14084, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.160e+03, 2.160e+03, 1.013e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.404e+03, 2.808e+03, 6.660e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.820e+02],\n",
       "       [3.240e+02, 3.240e+02, 1.013e+01, ..., 0.000e+00, 1.000e+00,\n",
       "        3.340e+02],\n",
       "       ...,\n",
       "       [1.080e+03, 1.080e+03, 6.550e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        2.900e+01],\n",
       "       [2.160e+03, 2.160e+03, 6.140e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.620e+03, 1.620e+03, 5.330e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        9.000e+01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_one_targets = int(np.sum(target))\n",
    "\n",
    "# zero_targets_counter = 0\n",
    "\n",
    "# indices_to_remove = []\n",
    "\n",
    "# for i in range(target.shape[0]):\n",
    "#     if target[i] == 0:\n",
    "#         zero_targets_counter += 1\n",
    "#         if zero_targets_counter > num_one_targets:\n",
    "#             indices_to_remove.append(i)\n",
    "\n",
    "# unscaled_inputs_equal_priors = np.delete(unscaled_input , indices_to_remove , axis=0)\n",
    "# targets_equal_priors = np.delete(target , indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12768719,  0.7351559 ,  0.61364906, ..., -0.44129834,\n",
       "        -0.14873032, -0.70217541],\n",
       "       [-0.37135283,  1.72474784, -0.08999108, ..., -0.44129834,\n",
       "        -0.14873032,  1.36121133],\n",
       "       [-2.51283858, -2.06868796,  0.61364906, ..., -0.44129834,\n",
       "         1.96928571,  3.08447937],\n",
       "       ...,\n",
       "       [-1.01379856, -0.91416402, -0.11229667, ..., -0.44129834,\n",
       "        -0.14873032, -0.37339401],\n",
       "       [ 1.12768719,  0.7351559 , -0.19543571, ..., -0.44129834,\n",
       "        -0.14873032, -0.70217541],\n",
       "       [ 0.05694432, -0.08950406, -0.359686  , ..., -0.44129834,\n",
       "        -0.14873032,  0.31818067]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_input = preprocessing.scale(unscaled_input)\n",
    "scaled_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(scaled_input , target , test_size = 0.25 , random_state = 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 50\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "                            #tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu' , input_dim = 10),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size , activation='sigmoid')   \n",
    "    \n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam' , loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10563 samples\n",
      "Epoch 1/100\n",
      "10563/10563 [==============================] - 1s 104us/sample - loss: 1.2666 - accuracy: 0.8012\n",
      "Epoch 2/100\n",
      "10563/10563 [==============================] - 1s 51us/sample - loss: 0.3488 - accuracy: 0.8425\n",
      "Epoch 3/100\n",
      "10563/10563 [==============================] - 1s 49us/sample - loss: 0.3160 - accuracy: 0.8477\n",
      "Epoch 4/100\n",
      "10563/10563 [==============================] - 1s 54us/sample - loss: 0.3031 - accuracy: 0.8570\n",
      "Epoch 5/100\n",
      "10563/10563 [==============================] - 1s 50us/sample - loss: 0.2968 - accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "10563/10563 [==============================] - 1s 56us/sample - loss: 0.2918 - accuracy: 0.8761\n",
      "Epoch 7/100\n",
      "10563/10563 [==============================] - 1s 55us/sample - loss: 0.2602 - accuracy: 0.9021\n",
      "Epoch 8/100\n",
      "10563/10563 [==============================] - 1s 66us/sample - loss: 0.2479 - accuracy: 0.9056\n",
      "Epoch 9/100\n",
      "10563/10563 [==============================] - 1s 69us/sample - loss: 0.2423 - accuracy: 0.9056\n",
      "Epoch 10/100\n",
      "10563/10563 [==============================] - 1s 54us/sample - loss: 0.2378 - accuracy: 0.9067\n",
      "Epoch 11/100\n",
      "10563/10563 [==============================] - 1s 60us/sample - loss: 0.2371 - accuracy: 0.9074\n",
      "Epoch 12/100\n",
      "10563/10563 [==============================] - 1s 52us/sample - loss: 0.2353 - accuracy: 0.9080\n",
      "Epoch 13/100\n",
      "10563/10563 [==============================] - 1s 62us/sample - loss: 0.2351 - accuracy: 0.9086\n",
      "Epoch 14/100\n",
      "10563/10563 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.90 - 1s 71us/sample - loss: 0.2317 - accuracy: 0.9097\n",
      "Epoch 15/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2318 - accuracy: 0.9099\n",
      "Epoch 16/100\n",
      "10563/10563 [==============================] - 2s 209us/sample - loss: 0.2323 - accuracy: 0.9097 - loss: 0.2319 \n",
      "Epoch 17/100\n",
      "10563/10563 [==============================] - 1s 111us/sample - loss: 0.2317 - accuracy: 0.9097\n",
      "Epoch 18/100\n",
      "10563/10563 [==============================] - 1s 124us/sample - loss: 0.2317 - accuracy: 0.9097\n",
      "Epoch 19/100\n",
      "10563/10563 [==============================] - 1s 71us/sample - loss: 0.2293 - accuracy: 0.9094\n",
      "Epoch 20/100\n",
      "10563/10563 [==============================] - 1s 100us/sample - loss: 0.2285 - accuracy: 0.9121\n",
      "Epoch 21/100\n",
      "10563/10563 [==============================] - 1s 115us/sample - loss: 0.2271 - accuracy: 0.9106\n",
      "Epoch 22/100\n",
      "10563/10563 [==============================] - 1s 109us/sample - loss: 0.2281 - accuracy: 0.9126 - loss: 0.2276 - accuracy\n",
      "Epoch 23/100\n",
      "10563/10563 [==============================] - 1s 111us/sample - loss: 0.2266 - accuracy: 0.9113 - loss: 0.2268 - accuracy: 0.91\n",
      "Epoch 24/100\n",
      "10563/10563 [==============================] - 1s 99us/sample - loss: 0.2260 - accuracy: 0.9114\n",
      "Epoch 25/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2254 - accuracy: 0.9122\n",
      "Epoch 26/100\n",
      "10563/10563 [==============================] - 1s 105us/sample - loss: 0.2278 - accuracy: 0.9094\n",
      "Epoch 27/100\n",
      "10563/10563 [==============================] - 1s 119us/sample - loss: 0.2245 - accuracy: 0.9118\n",
      "Epoch 28/100\n",
      "10563/10563 [==============================] - 1s 111us/sample - loss: 0.2237 - accuracy: 0.9118\n",
      "Epoch 29/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2252 - accuracy: 0.9111\n",
      "Epoch 30/100\n",
      "10563/10563 [==============================] - 1s 98us/sample - loss: 0.2259 - accuracy: 0.9124\n",
      "Epoch 31/100\n",
      "10563/10563 [==============================] - 1s 82us/sample - loss: 0.2223 - accuracy: 0.9134\n",
      "Epoch 32/100\n",
      "10563/10563 [==============================] - 1s 95us/sample - loss: 0.2223 - accuracy: 0.9120\n",
      "Epoch 33/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2250 - accuracy: 0.9148\n",
      "Epoch 34/100\n",
      "10563/10563 [==============================] - 1s 96us/sample - loss: 0.2234 - accuracy: 0.9123\n",
      "Epoch 35/100\n",
      "10563/10563 [==============================] - 1s 91us/sample - loss: 0.2204 - accuracy: 0.9133\n",
      "Epoch 36/100\n",
      "10563/10563 [==============================] - 1s 85us/sample - loss: 0.2227 - accuracy: 0.9128\n",
      "Epoch 37/100\n",
      "10563/10563 [==============================] - 1s 81us/sample - loss: 0.2216 - accuracy: 0.9139\n",
      "Epoch 38/100\n",
      "10563/10563 [==============================] - 1s 80us/sample - loss: 0.2229 - accuracy: 0.9111\n",
      "Epoch 39/100\n",
      "10563/10563 [==============================] - 1s 83us/sample - loss: 0.2206 - accuracy: 0.9122s -\n",
      "Epoch 40/100\n",
      "10563/10563 [==============================] - 1s 78us/sample - loss: 0.2208 - accuracy: 0.9130\n",
      "Epoch 41/100\n",
      "10563/10563 [==============================] - 1s 78us/sample - loss: 0.2234 - accuracy: 0.9123\n",
      "Epoch 42/100\n",
      "10563/10563 [==============================] - 1s 88us/sample - loss: 0.2213 - accuracy: 0.9132\n",
      "Epoch 43/100\n",
      "10563/10563 [==============================] - 1s 77us/sample - loss: 0.2231 - accuracy: 0.9138\n",
      "Epoch 44/100\n",
      "10563/10563 [==============================] - 1s 84us/sample - loss: 0.2199 - accuracy: 0.9135\n",
      "Epoch 45/100\n",
      "10563/10563 [==============================] - 1s 77us/sample - loss: 0.2195 - accuracy: 0.9126\n",
      "Epoch 46/100\n",
      "10563/10563 [==============================] - 1s 85us/sample - loss: 0.2194 - accuracy: 0.9132\n",
      "Epoch 47/100\n",
      "10563/10563 [==============================] - 1s 94us/sample - loss: 0.2207 - accuracy: 0.9128\n",
      "Epoch 48/100\n",
      "10563/10563 [==============================] - 1s 74us/sample - loss: 0.2215 - accuracy: 0.9136\n",
      "Epoch 49/100\n",
      "10563/10563 [==============================] - 1s 89us/sample - loss: 0.2198 - accuracy: 0.9126\n",
      "Epoch 50/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2195 - accuracy: 0.9139\n",
      "Epoch 51/100\n",
      "10563/10563 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.91 - 1s 59us/sample - loss: 0.2185 - accuracy: 0.9130\n",
      "Epoch 52/100\n",
      "10563/10563 [==============================] - 1s 93us/sample - loss: 0.2187 - accuracy: 0.9137\n",
      "Epoch 53/100\n",
      "10563/10563 [==============================] - 1s 101us/sample - loss: 0.2204 - accuracy: 0.9137\n",
      "Epoch 54/100\n",
      "10563/10563 [==============================] - 1s 68us/sample - loss: 0.2195 - accuracy: 0.9135\n",
      "Epoch 55/100\n",
      "10563/10563 [==============================] - 1s 69us/sample - loss: 0.2174 - accuracy: 0.9161\n",
      "Epoch 56/100\n",
      "10563/10563 [==============================] - 1s 66us/sample - loss: 0.2177 - accuracy: 0.9130\n",
      "Epoch 57/100\n",
      "10563/10563 [==============================] - 1s 66us/sample - loss: 0.2189 - accuracy: 0.9156\n",
      "Epoch 58/100\n",
      "10563/10563 [==============================] - 1s 72us/sample - loss: 0.2199 - accuracy: 0.9121\n",
      "Epoch 59/100\n",
      "10563/10563 [==============================] - 1s 73us/sample - loss: 0.2181 - accuracy: 0.9137\n",
      "Epoch 60/100\n",
      "10563/10563 [==============================] - 1s 70us/sample - loss: 0.2181 - accuracy: 0.9149\n",
      "Epoch 61/100\n",
      "10563/10563 [==============================] - 1s 68us/sample - loss: 0.2162 - accuracy: 0.9153\n",
      "Epoch 62/100\n",
      "10563/10563 [==============================] - 1s 66us/sample - loss: 0.2182 - accuracy: 0.9143\n",
      "Epoch 63/100\n",
      "10563/10563 [==============================] - 1s 65us/sample - loss: 0.2164 - accuracy: 0.9145\n",
      "Epoch 64/100\n",
      "10563/10563 [==============================] - 1s 69us/sample - loss: 0.2188 - accuracy: 0.9135\n",
      "Epoch 65/100\n",
      "10563/10563 [==============================] - 1s 55us/sample - loss: 0.2164 - accuracy: 0.9142\n",
      "Epoch 66/100\n",
      "10563/10563 [==============================] - 1s 47us/sample - loss: 0.2164 - accuracy: 0.9139\n",
      "Epoch 67/100\n",
      "10563/10563 [==============================] - 0s 47us/sample - loss: 0.2168 - accuracy: 0.9159\n",
      "Epoch 68/100\n",
      "10563/10563 [==============================] - 1s 51us/sample - loss: 0.2178 - accuracy: 0.9134\n",
      "Epoch 69/100\n",
      "10563/10563 [==============================] - 1s 48us/sample - loss: 0.2197 - accuracy: 0.9131\n",
      "Epoch 70/100\n",
      "10563/10563 [==============================] - 0s 47us/sample - loss: 0.2181 - accuracy: 0.9140\n",
      "Epoch 71/100\n",
      "10563/10563 [==============================] - 0s 47us/sample - loss: 0.2168 - accuracy: 0.9139\n",
      "Epoch 72/100\n",
      "10563/10563 [==============================] - 0s 46us/sample - loss: 0.2188 - accuracy: 0.9143\n",
      "Epoch 73/100\n",
      "10563/10563 [==============================] - 0s 45us/sample - loss: 0.2157 - accuracy: 0.9140\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10563/10563 [==============================] - 0s 44us/sample - loss: 0.2171 - accuracy: 0.9145\n",
      "Epoch 75/100\n",
      "10563/10563 [==============================] - 0s 44us/sample - loss: 0.2181 - accuracy: 0.9155\n",
      "Epoch 76/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2152 - accuracy: 0.9150\n",
      "Epoch 77/100\n",
      "10563/10563 [==============================] - 1s 86us/sample - loss: 0.2167 - accuracy: 0.9135s - loss:\n",
      "Epoch 78/100\n",
      "10563/10563 [==============================] - 1s 62us/sample - loss: 0.2178 - accuracy: 0.9138\n",
      "Epoch 79/100\n",
      "10563/10563 [==============================] - 1s 48us/sample - loss: 0.2175 - accuracy: 0.9144\n",
      "Epoch 80/100\n",
      "10563/10563 [==============================] - 1s 53us/sample - loss: 0.2167 - accuracy: 0.9130\n",
      "Epoch 81/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2168 - accuracy: 0.9149\n",
      "Epoch 82/100\n",
      "10563/10563 [==============================] - 1s 52us/sample - loss: 0.2176 - accuracy: 0.9151\n",
      "Epoch 83/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2137 - accuracy: 0.9157s - loss: 0.2088 - \n",
      "Epoch 84/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2156 - accuracy: 0.9156\n",
      "Epoch 85/100\n",
      "10563/10563 [==============================] - 0s 44us/sample - loss: 0.2164 - accuracy: 0.9146\n",
      "Epoch 86/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2155 - accuracy: 0.9152\n",
      "Epoch 87/100\n",
      "10563/10563 [==============================] - 1s 51us/sample - loss: 0.2141 - accuracy: 0.9153\n",
      "Epoch 88/100\n",
      "10563/10563 [==============================] - 1s 48us/sample - loss: 0.2164 - accuracy: 0.9141\n",
      "Epoch 89/100\n",
      "10563/10563 [==============================] - 0s 45us/sample - loss: 0.2155 - accuracy: 0.9137\n",
      "Epoch 90/100\n",
      "10563/10563 [==============================] - 1s 48us/sample - loss: 0.2136 - accuracy: 0.9158\n",
      "Epoch 91/100\n",
      "10563/10563 [==============================] - 1s 68us/sample - loss: 0.2158 - accuracy: 0.9158\n",
      "Epoch 92/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2145 - accuracy: 0.9156\n",
      "Epoch 93/100\n",
      "10563/10563 [==============================] - 1s 62us/sample - loss: 0.2164 - accuracy: 0.9138\n",
      "Epoch 94/100\n",
      "10563/10563 [==============================] - 1s 49us/sample - loss: 0.2145 - accuracy: 0.9150\n",
      "Epoch 95/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2174 - accuracy: 0.9141\n",
      "Epoch 96/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2184 - accuracy: 0.9154\n",
      "Epoch 97/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2148 - accuracy: 0.9150\n",
      "Epoch 98/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2160 - accuracy: 0.9154\n",
      "Epoch 99/100\n",
      "10563/10563 [==============================] - 0s 42us/sample - loss: 0.2145 - accuracy: 0.9149\n",
      "Epoch 100/100\n",
      "10563/10563 [==============================] - 0s 43us/sample - loss: 0.2149 - accuracy: 0.9158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2200e163e88>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train ,  y_train , batch_size = 100 , epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3521/3521 [==============================] - 1s 211us/sample - loss: 0.2406 - accuracy: 0.9068\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = model.evaluate(x_test , y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
