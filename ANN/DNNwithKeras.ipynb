{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('G:/Software/Neural Network/2/Tensorflow and Keras For Neural Networks and Deep Learning/9. Deep Learning For Tensorflow & Keras/pima-indians-diabetes.csv' , delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    6  148  72  35    0  33.6  0.627  50  1\n",
       "0   1   85  66  29    0  26.6  0.351  31  0\n",
       "1   8  183  64   0    0  23.3  0.672  32  1\n",
       "2   1   89  66  23   94  28.1  0.167  21  0\n",
       "3   0  137  40  35  168  43.1  2.288  33  1\n",
       "4   5  116  74   0    0  25.6  0.201  30  0\n",
       "5   3   78  50  32   88  31.0  0.248  26  1\n",
       "6  10  115   0   0    0  35.3  0.134  29  0\n",
       "7   2  197  70  45  543  30.5  0.158  53  1\n",
       "8   8  125  96   0    0   0.0  0.232  54  1\n",
       "9   4  110  92   0    0  37.6  0.191  30  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8]\n",
    "Y = df.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627  50\n",
       "0     1   85  66  29    0  26.6  0.351  31\n",
       "1     8  183  64   0    0  23.3  0.672  32\n",
       "2     1   89  66  23   94  28.1  0.167  21\n",
       "3     0  137  40  35  168  43.1  2.288  33\n",
       "4     5  116  74   0    0  25.6  0.201  30\n",
       "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
       "762  10  101  76  48  180  32.9  0.171  63\n",
       "763   2  122  70  27    0  36.8  0.340  27\n",
       "764   5  121  72  23  112  26.2  0.245  30\n",
       "765   1  126  60   0    0  30.1  0.349  47\n",
       "766   1   93  70  31    0  30.4  0.315  23\n",
       "\n",
       "[767 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "767/767 [==============================] - 2s 2ms/step - loss: 10.2264 - accuracy: 0.4498\n",
      "Epoch 2/150\n",
      "767/767 [==============================] - 1s 681us/step - loss: 2.1105 - accuracy: 0.5411\n",
      "Epoch 3/150\n",
      "767/767 [==============================] - 1s 734us/step - loss: 1.2457 - accuracy: 0.6050\n",
      "Epoch 4/150\n",
      "767/767 [==============================] - 1s 883us/step - loss: 0.9815 - accuracy: 0.6323\n",
      "Epoch 5/150\n",
      "767/767 [==============================] - 1s 759us/step - loss: 0.8885 - accuracy: 0.6415\n",
      "Epoch 6/150\n",
      "767/767 [==============================] - 1s 920us/step - loss: 0.8350 - accuracy: 0.6623\n",
      "Epoch 7/150\n",
      "767/767 [==============================] - 1s 782us/step - loss: 0.8433 - accuracy: 0.6610\n",
      "Epoch 8/150\n",
      "767/767 [==============================] - 1s 984us/step - loss: 0.7556 - accuracy: 0.6728\n",
      "Epoch 9/150\n",
      "767/767 [==============================] - 1s 1ms/step - loss: 0.7325 - accuracy: 0.6884\n",
      "Epoch 10/150\n",
      "767/767 [==============================] - 1s 798us/step - loss: 0.7635 - accuracy: 0.6571\n",
      "Epoch 11/150\n",
      "767/767 [==============================] - 1s 822us/step - loss: 0.7432 - accuracy: 0.6532\n",
      "Epoch 12/150\n",
      "767/767 [==============================] - 1s 869us/step - loss: 0.7089 - accuracy: 0.6949\n",
      "Epoch 13/150\n",
      "767/767 [==============================] - 1s 733us/step - loss: 0.6816 - accuracy: 0.7119\n",
      "Epoch 14/150\n",
      "767/767 [==============================] - 1s 791us/step - loss: 0.7181 - accuracy: 0.6936\n",
      "Epoch 15/150\n",
      "767/767 [==============================] - 1s 1ms/step - loss: 0.6744 - accuracy: 0.7027\n",
      "Epoch 16/150\n",
      "767/767 [==============================] - 1s 869us/step - loss: 0.6640 - accuracy: 0.7001\n",
      "Epoch 17/150\n",
      "767/767 [==============================] - 1s 803us/step - loss: 0.6857 - accuracy: 0.7001\n",
      "Epoch 18/150\n",
      "767/767 [==============================] - 1s 831us/step - loss: 0.6747 - accuracy: 0.6923\n",
      "Epoch 19/150\n",
      "767/767 [==============================] - 1s 936us/step - loss: 0.6503 - accuracy: 0.7080\n",
      "Epoch 20/150\n",
      "767/767 [==============================] - 1s 956us/step - loss: 0.6563 - accuracy: 0.7145\n",
      "Epoch 21/150\n",
      "767/767 [==============================] - 0s 575us/step - loss: 0.6207 - accuracy: 0.7210\n",
      "Epoch 22/150\n",
      "767/767 [==============================] - 0s 559us/step - loss: 0.6615 - accuracy: 0.6897\n",
      "Epoch 23/150\n",
      "767/767 [==============================] - 0s 572us/step - loss: 0.6091 - accuracy: 0.7171\n",
      "Epoch 24/150\n",
      "767/767 [==============================] - 0s 547us/step - loss: 0.6295 - accuracy: 0.7080\n",
      "Epoch 25/150\n",
      "767/767 [==============================] - 0s 553us/step - loss: 0.6470 - accuracy: 0.7119\n",
      "Epoch 26/150\n",
      "767/767 [==============================] - 1s 818us/step - loss: 0.6154 - accuracy: 0.6962\n",
      "Epoch 27/150\n",
      "767/767 [==============================] - 1s 1ms/step - loss: 0.6479 - accuracy: 0.6962\n",
      "Epoch 28/150\n",
      "767/767 [==============================] - 1s 798us/step - loss: 0.6189 - accuracy: 0.7027\n",
      "Epoch 29/150\n",
      "767/767 [==============================] - 1s 818us/step - loss: 0.6053 - accuracy: 0.7171\n",
      "Epoch 30/150\n",
      "767/767 [==============================] - 1s 765us/step - loss: 0.6071 - accuracy: 0.7171\n",
      "Epoch 31/150\n",
      "767/767 [==============================] - 1s 754us/step - loss: 0.5990 - accuracy: 0.6975\n",
      "Epoch 32/150\n",
      "767/767 [==============================] - 1s 761us/step - loss: 0.5932 - accuracy: 0.7275\n",
      "Epoch 33/150\n",
      "767/767 [==============================] - 1s 785us/step - loss: 0.5819 - accuracy: 0.7366\n",
      "Epoch 34/150\n",
      "767/767 [==============================] - 1s 809us/step - loss: 0.6085 - accuracy: 0.7327\n",
      "Epoch 35/150\n",
      "767/767 [==============================] - 1s 840us/step - loss: 0.6080 - accuracy: 0.7132\n",
      "Epoch 36/150\n",
      "767/767 [==============================] - 1s 916us/step - loss: 0.5851 - accuracy: 0.7093\n",
      "Epoch 37/150\n",
      "767/767 [==============================] - 1s 821us/step - loss: 0.5967 - accuracy: 0.7132\n",
      "Epoch 38/150\n",
      "767/767 [==============================] - 1s 787us/step - loss: 0.5824 - accuracy: 0.7301\n",
      "Epoch 39/150\n",
      "767/767 [==============================] - 1s 729us/step - loss: 0.6084 - accuracy: 0.7106\n",
      "Epoch 40/150\n",
      "767/767 [==============================] - 1s 769us/step - loss: 0.5815 - accuracy: 0.7314\n",
      "Epoch 41/150\n",
      "767/767 [==============================] - 1s 873us/step - loss: 0.6053 - accuracy: 0.7262\n",
      "Epoch 42/150\n",
      "767/767 [==============================] - 1s 894us/step - loss: 0.5746 - accuracy: 0.72750s - loss: 0.5424 - accuracy\n",
      "Epoch 43/150\n",
      "767/767 [==============================] - 1s 770us/step - loss: 0.5724 - accuracy: 0.7432\n",
      "Epoch 44/150\n",
      "767/767 [==============================] - 0s 567us/step - loss: 0.5659 - accuracy: 0.7288\n",
      "Epoch 45/150\n",
      "767/767 [==============================] - 1s 673us/step - loss: 0.6192 - accuracy: 0.6936\n",
      "Epoch 46/150\n",
      "767/767 [==============================] - 0s 557us/step - loss: 0.5978 - accuracy: 0.7040\n",
      "Epoch 47/150\n",
      "767/767 [==============================] - 1s 936us/step - loss: 0.5991 - accuracy: 0.7066\n",
      "Epoch 48/150\n",
      "767/767 [==============================] - 1s 845us/step - loss: 0.5855 - accuracy: 0.7066\n",
      "Epoch 49/150\n",
      "767/767 [==============================] - 1s 873us/step - loss: 0.5730 - accuracy: 0.7327\n",
      "Epoch 50/150\n",
      "767/767 [==============================] - 1s 960us/step - loss: 0.5605 - accuracy: 0.72490s - loss: 0.6\n",
      "Epoch 51/150\n",
      "767/767 [==============================] - 1s 768us/step - loss: 0.5707 - accuracy: 0.7158\n",
      "Epoch 52/150\n",
      "767/767 [==============================] - 1s 907us/step - loss: 0.5744 - accuracy: 0.7236\n",
      "Epoch 53/150\n",
      "767/767 [==============================] - 1s 991us/step - loss: 0.5458 - accuracy: 0.7392\n",
      "Epoch 54/150\n",
      "767/767 [==============================] - 1s 1ms/step - loss: 0.5742 - accuracy: 0.7249: 0s - loss: 0.510\n",
      "Epoch 55/150\n",
      "767/767 [==============================] - 1s 837us/step - loss: 0.5445 - accuracy: 0.7419\n",
      "Epoch 56/150\n",
      "767/767 [==============================] - 0s 624us/step - loss: 0.5711 - accuracy: 0.7458\n",
      "Epoch 57/150\n",
      "767/767 [==============================] - 1s 975us/step - loss: 0.5502 - accuracy: 0.7405\n",
      "Epoch 58/150\n",
      "767/767 [==============================] - 0s 529us/step - loss: 0.5788 - accuracy: 0.7262\n",
      "Epoch 59/150\n",
      "767/767 [==============================] - 0s 536us/step - loss: 0.5772 - accuracy: 0.7275\n",
      "Epoch 60/150\n",
      "767/767 [==============================] - 0s 507us/step - loss: 0.5843 - accuracy: 0.7158\n",
      "Epoch 61/150\n",
      "767/767 [==============================] - 0s 511us/step - loss: 0.5767 - accuracy: 0.7288\n",
      "Epoch 62/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5781 - accuracy: 0.7093\n",
      "Epoch 63/150\n",
      "767/767 [==============================] - 0s 510us/step - loss: 0.5558 - accuracy: 0.7458\n",
      "Epoch 64/150\n",
      "767/767 [==============================] - 0s 516us/step - loss: 0.5587 - accuracy: 0.7301\n",
      "Epoch 65/150\n",
      "767/767 [==============================] - 0s 508us/step - loss: 0.5385 - accuracy: 0.7484\n",
      "Epoch 66/150\n",
      "767/767 [==============================] - 0s 511us/step - loss: 0.5433 - accuracy: 0.7536\n",
      "Epoch 67/150\n",
      "767/767 [==============================] - 0s 506us/step - loss: 0.5303 - accuracy: 0.7601\n",
      "Epoch 68/150\n",
      "767/767 [==============================] - 0s 512us/step - loss: 0.5809 - accuracy: 0.7262\n",
      "Epoch 69/150\n",
      "767/767 [==============================] - 0s 520us/step - loss: 0.5368 - accuracy: 0.7353\n",
      "Epoch 70/150\n",
      "767/767 [==============================] - 0s 509us/step - loss: 0.5299 - accuracy: 0.7458\n",
      "Epoch 71/150\n",
      "767/767 [==============================] - 0s 503us/step - loss: 0.5468 - accuracy: 0.7432\n",
      "Epoch 72/150\n",
      "767/767 [==============================] - 0s 528us/step - loss: 0.5993 - accuracy: 0.7027\n",
      "Epoch 73/150\n",
      "767/767 [==============================] - 0s 518us/step - loss: 0.5516 - accuracy: 0.7405\n",
      "Epoch 74/150\n",
      "767/767 [==============================] - 0s 506us/step - loss: 0.5413 - accuracy: 0.7379\n",
      "Epoch 75/150\n",
      "767/767 [==============================] - 0s 504us/step - loss: 0.5705 - accuracy: 0.7419\n",
      "Epoch 76/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5425 - accuracy: 0.7288\n",
      "Epoch 77/150\n",
      "767/767 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.71 - 0s 519us/step - loss: 0.5481 - accuracy: 0.7197\n",
      "Epoch 78/150\n",
      "767/767 [==============================] - 0s 503us/step - loss: 0.5350 - accuracy: 0.7314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150\n",
      "767/767 [==============================] - 0s 507us/step - loss: 0.5419 - accuracy: 0.7340\n",
      "Epoch 80/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5365 - accuracy: 0.7366\n",
      "Epoch 81/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5250 - accuracy: 0.7601\n",
      "Epoch 82/150\n",
      "767/767 [==============================] - 0s 508us/step - loss: 0.5219 - accuracy: 0.7445\n",
      "Epoch 83/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5438 - accuracy: 0.7249\n",
      "Epoch 84/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5242 - accuracy: 0.7627\n",
      "Epoch 85/150\n",
      "767/767 [==============================] - 0s 492us/step - loss: 0.5667 - accuracy: 0.7314\n",
      "Epoch 86/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5256 - accuracy: 0.7366\n",
      "Epoch 87/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5442 - accuracy: 0.7197\n",
      "Epoch 88/150\n",
      "767/767 [==============================] - 0s 502us/step - loss: 0.5527 - accuracy: 0.7419\n",
      "Epoch 89/150\n",
      "767/767 [==============================] - 0s 503us/step - loss: 0.5517 - accuracy: 0.7366\n",
      "Epoch 90/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5279 - accuracy: 0.7575\n",
      "Epoch 91/150\n",
      "767/767 [==============================] - 0s 507us/step - loss: 0.5338 - accuracy: 0.7275\n",
      "Epoch 92/150\n",
      "767/767 [==============================] - 0s 514us/step - loss: 0.5141 - accuracy: 0.7536\n",
      "Epoch 93/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5389 - accuracy: 0.7484\n",
      "Epoch 94/150\n",
      "767/767 [==============================] - 0s 506us/step - loss: 0.5554 - accuracy: 0.7158\n",
      "Epoch 95/150\n",
      "767/767 [==============================] - 0s 511us/step - loss: 0.5317 - accuracy: 0.75100s - loss: 0.4876 - ac\n",
      "Epoch 96/150\n",
      "767/767 [==============================] - 0s 510us/step - loss: 0.5525 - accuracy: 0.7262\n",
      "Epoch 97/150\n",
      "767/767 [==============================] - 0s 515us/step - loss: 0.5505 - accuracy: 0.7353\n",
      "Epoch 98/150\n",
      "767/767 [==============================] - 0s 505us/step - loss: 0.5205 - accuracy: 0.7445\n",
      "Epoch 99/150\n",
      "767/767 [==============================] - 0s 499us/step - loss: 0.5282 - accuracy: 0.7432\n",
      "Epoch 100/150\n",
      "767/767 [==============================] - 0s 502us/step - loss: 0.5204 - accuracy: 0.7510\n",
      "Epoch 101/150\n",
      "767/767 [==============================] - 0s 497us/step - loss: 0.5274 - accuracy: 0.7445\n",
      "Epoch 102/150\n",
      "767/767 [==============================] - 0s 515us/step - loss: 0.5231 - accuracy: 0.7301\n",
      "Epoch 103/150\n",
      "767/767 [==============================] - 0s 498us/step - loss: 0.5108 - accuracy: 0.7405\n",
      "Epoch 104/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5169 - accuracy: 0.7484\n",
      "Epoch 105/150\n",
      "767/767 [==============================] - 0s 494us/step - loss: 0.5164 - accuracy: 0.7692\n",
      "Epoch 106/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5369 - accuracy: 0.7340\n",
      "Epoch 107/150\n",
      "767/767 [==============================] - 0s 515us/step - loss: 0.5201 - accuracy: 0.7379\n",
      "Epoch 108/150\n",
      "767/767 [==============================] - 0s 494us/step - loss: 0.5171 - accuracy: 0.7484\n",
      "Epoch 109/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5160 - accuracy: 0.7666\n",
      "Epoch 110/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5306 - accuracy: 0.7353\n",
      "Epoch 111/150\n",
      "767/767 [==============================] - 0s 490us/step - loss: 0.5187 - accuracy: 0.7432\n",
      "Epoch 112/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5314 - accuracy: 0.7445\n",
      "Epoch 113/150\n",
      "767/767 [==============================] - 0s 503us/step - loss: 0.5145 - accuracy: 0.7692\n",
      "Epoch 114/150\n",
      "767/767 [==============================] - 0s 492us/step - loss: 0.5441 - accuracy: 0.7327\n",
      "Epoch 115/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5383 - accuracy: 0.7484\n",
      "Epoch 116/150\n",
      "767/767 [==============================] - 0s 498us/step - loss: 0.5295 - accuracy: 0.7432\n",
      "Epoch 117/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5296 - accuracy: 0.7432\n",
      "Epoch 118/150\n",
      "767/767 [==============================] - 0s 494us/step - loss: 0.5160 - accuracy: 0.7301\n",
      "Epoch 119/150\n",
      "767/767 [==============================] - 0s 506us/step - loss: 0.5065 - accuracy: 0.7601\n",
      "Epoch 120/150\n",
      "767/767 [==============================] - 0s 497us/step - loss: 0.5155 - accuracy: 0.7601\n",
      "Epoch 121/150\n",
      "767/767 [==============================] - 0s 493us/step - loss: 0.5047 - accuracy: 0.7601\n",
      "Epoch 122/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5215 - accuracy: 0.7536\n",
      "Epoch 123/150\n",
      "767/767 [==============================] - 0s 497us/step - loss: 0.4959 - accuracy: 0.7666\n",
      "Epoch 124/150\n",
      "767/767 [==============================] - 0s 493us/step - loss: 0.5277 - accuracy: 0.7458\n",
      "Epoch 125/150\n",
      "767/767 [==============================] - 0s 490us/step - loss: 0.4971 - accuracy: 0.7458\n",
      "Epoch 126/150\n",
      "767/767 [==============================] - 0s 503us/step - loss: 0.5413 - accuracy: 0.7366\n",
      "Epoch 127/150\n",
      "767/767 [==============================] - 0s 492us/step - loss: 0.5328 - accuracy: 0.7562\n",
      "Epoch 128/150\n",
      "767/767 [==============================] - 0s 512us/step - loss: 0.5053 - accuracy: 0.7562\n",
      "Epoch 129/150\n",
      "767/767 [==============================] - 0s 498us/step - loss: 0.5103 - accuracy: 0.7484\n",
      "Epoch 130/150\n",
      "767/767 [==============================] - 0s 501us/step - loss: 0.5227 - accuracy: 0.7562\n",
      "Epoch 131/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5259 - accuracy: 0.7484\n",
      "Epoch 132/150\n",
      "767/767 [==============================] - 0s 489us/step - loss: 0.5054 - accuracy: 0.7666\n",
      "Epoch 133/150\n",
      "767/767 [==============================] - 0s 497us/step - loss: 0.5178 - accuracy: 0.7536\n",
      "Epoch 134/150\n",
      "767/767 [==============================] - 0s 494us/step - loss: 0.4928 - accuracy: 0.7575\n",
      "Epoch 135/150\n",
      "767/767 [==============================] - 0s 490us/step - loss: 0.5026 - accuracy: 0.7575\n",
      "Epoch 136/150\n",
      "767/767 [==============================] - 0s 490us/step - loss: 0.5474 - accuracy: 0.7405\n",
      "Epoch 137/150\n",
      "767/767 [==============================] - 0s 492us/step - loss: 0.5010 - accuracy: 0.7731\n",
      "Epoch 138/150\n",
      "767/767 [==============================] - 0s 532us/step - loss: 0.5156 - accuracy: 0.7484\n",
      "Epoch 139/150\n",
      "767/767 [==============================] - 0s 498us/step - loss: 0.5274 - accuracy: 0.7510\n",
      "Epoch 140/150\n",
      "767/767 [==============================] - 0s 494us/step - loss: 0.4994 - accuracy: 0.7588\n",
      "Epoch 141/150\n",
      "767/767 [==============================] - 0s 501us/step - loss: 0.5098 - accuracy: 0.7523\n",
      "Epoch 142/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5105 - accuracy: 0.7653\n",
      "Epoch 143/150\n",
      "767/767 [==============================] - 0s 493us/step - loss: 0.4963 - accuracy: 0.7614\n",
      "Epoch 144/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5155 - accuracy: 0.7601\n",
      "Epoch 145/150\n",
      "767/767 [==============================] - 0s 492us/step - loss: 0.5013 - accuracy: 0.7705\n",
      "Epoch 146/150\n",
      "767/767 [==============================] - 0s 493us/step - loss: 0.4996 - accuracy: 0.7679\n",
      "Epoch 147/150\n",
      "767/767 [==============================] - 0s 499us/step - loss: 0.4963 - accuracy: 0.7718\n",
      "Epoch 148/150\n",
      "767/767 [==============================] - 0s 495us/step - loss: 0.5193 - accuracy: 0.7432\n",
      "Epoch 149/150\n",
      "767/767 [==============================] - 0s 497us/step - loss: 0.5145 - accuracy: 0.7679\n",
      "Epoch 150/150\n",
      "767/767 [==============================] - 0s 490us/step - loss: 0.5042 - accuracy: 0.7510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1645fa8e188>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767/767 [==============================] - 0s 114us/step\n",
      "\n",
      "accuracy: 76.53%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Wide&DeepLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
