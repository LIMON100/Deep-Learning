{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# mlp for regression with mse loss function\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.64516745,  0.76000873, -0.18010938, ..., -0.76479647,\n",
       "        -0.2088517 ,  1.04702956],\n",
       "       [ 1.91668806, -0.46635771,  1.19569536, ..., -0.70196101,\n",
       "         0.04332125,  0.27556296],\n",
       "       [-0.06519522,  0.31264841, -1.83288453, ...,  0.37878977,\n",
       "        -0.16435327,  0.65283426],\n",
       "       ...,\n",
       "       [ 1.26655465,  0.60740625, -0.95059999, ..., -1.45418616,\n",
       "        -1.29556648,  0.08245958],\n",
       "       [ 0.08499911, -0.01960806,  0.00857039, ...,  1.41668487,\n",
       "        -0.31452234, -1.43156124],\n",
       "       [ 1.58087206, -1.59253805,  0.33462076, ...,  1.6862182 ,\n",
       "        -1.88469796,  0.24021141]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "opt = SGD(lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "history = model.fit(trainX, trainy, validation_data = (testX , testy), epochs = 100, verbose = 0)\n",
    "\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squeare Logarithmic Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = StandardScaler().fit_transform(y.reshape(len(y),1))[:,0]\n",
    "\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "_, train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Mean Squared Error')\n",
    "pyplot.plot(history.history['mean_squared_error'], label='train')\n",
    "pyplot.plot(history.history['val_mean_squared_error'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "\n",
    "X , y = make_regression(n_samples = 1000 , n_features = 20 , noise = 0.1 , random_state = 1)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = StandardScaler().fit_transform(y.reshape(len(y) , 1))[: , 0]\n",
    "\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation = 'relu' , kernel_initializer = 'he_uniform'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "opt = SGD(lr = 0.01 , momentum = 0.9)\n",
    "model.compile(loss='mean_absolute_error', optimizer=opt, metrics=['mse'])\n",
    "\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "\n",
    "_, train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "_, test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Mean Squared Error')\n",
    "pyplot.plot(history.history['mean_squared_error'], label='train')\n",
    "pyplot.plot(history.history['val_mean_squared_error'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
