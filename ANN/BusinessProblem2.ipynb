{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "_CURRENT_SCRATCH_GRAPH = None\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('G:\\Software\\Machine learning\\Datasets\\Deep learning\\Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the dataset\n",
    "x = dataset.iloc[:, 3:12].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "x[:, 1] = labelencoder_X.fit_transform(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 'Female', ..., 1, 1, 1],\n",
       "       [608, 2, 'Female', ..., 1, 0, 1],\n",
       "       [502, 0, 'Female', ..., 3, 1, 0],\n",
       "       ...,\n",
       "       [709, 0, 'Female', ..., 1, 0, 1],\n",
       "       [772, 1, 'Male', ..., 2, 1, 0],\n",
       "       [792, 0, 'Female', ..., 1, 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X_1 = LabelEncoder()\n",
    "x[:, 2] = labelencoder_X_1.fit_transform(x[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 0, 0, ..., 1, 1, 1],\n",
       "       [608, 2, 0, ..., 1, 0, 1],\n",
       "       [502, 0, 0, ..., 3, 1, 0],\n",
       "       ...,\n",
       "       [709, 0, 0, ..., 1, 0, 1],\n",
       "       [772, 1, 1, ..., 2, 1, 0],\n",
       "       [792, 0, 0, ..., 1, 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmudur Limon\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Mahmudur Limon\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "x = onehotencoder.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 1., ..., 1., 0., 1.],\n",
       "       [1., 0., 0., ..., 3., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 1., 0., ..., 2., 1., 0.],\n",
       "       [1., 0., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0., 619., ...,   1.,   1.,   1.],\n",
       "       [  0.,   1., 608., ...,   1.,   0.,   1.],\n",
       "       [  0.,   0., 502., ...,   3.,   1.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0., 709., ...,   1.,   0.,   1.],\n",
       "       [  1.,   0., 772., ...,   2.,   1.,   0.],\n",
       "       [  0.,   0., 792., ...,   1.,   1.,   0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 3., 0., 0.],\n",
       "       [1., 0., 0., ..., 2., 1., 0.],\n",
       "       [0., 0., 1., ..., 2., 1., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 2., 1., 0.],\n",
       "       [0., 0., 1., ..., 2., 1., 1.],\n",
       "       [0., 1., 0., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01558815,  1.76021608, -0.57468161, ...,  2.53503394,\n",
       "        -1.55362351, -1.03446007],\n",
       "       [ 0.98465111, -0.56811207, -0.57468161, ...,  0.80424154,\n",
       "         0.64365658, -1.03446007],\n",
       "       [-1.01558815, -0.56811207,  1.74009395, ...,  0.80424154,\n",
       "         0.64365658,  0.96668786],\n",
       "       ...,\n",
       "       [ 0.98465111, -0.56811207, -0.57468161, ...,  0.80424154,\n",
       "         0.64365658, -1.03446007],\n",
       "       [-1.01558815, -0.56811207,  1.74009395, ...,  0.80424154,\n",
       "         0.64365658,  0.96668786],\n",
       "       [-1.01558815,  1.76021608, -0.57468161, ..., -0.92655087,\n",
       "         0.64365658, -1.03446007]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01558815,  1.76021608, -0.57468161, ..., -0.92655087,\n",
       "         0.64365658,  0.96668786],\n",
       "       [ 0.98465111, -0.56811207, -0.57468161, ..., -0.92655087,\n",
       "         0.64365658, -1.03446007],\n",
       "       [-1.01558815, -0.56811207,  1.74009395, ..., -0.92655087,\n",
       "         0.64365658,  0.96668786],\n",
       "       ...,\n",
       "       [ 0.98465111, -0.56811207, -0.57468161, ..., -0.92655087,\n",
       "         0.64365658, -1.03446007],\n",
       "       [-1.01558815,  1.76021608, -0.57468161, ...,  0.80424154,\n",
       "         0.64365658, -1.03446007],\n",
       "       [ 0.98465111, -0.56811207, -0.57468161, ..., -0.92655087,\n",
       "        -1.55362351, -1.03446007]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmudur Limon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=11, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# input layer and first hidden layer.\n",
    "classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu' , input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmudur Limon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Add second hidden layer\n",
    "classifier.add(Dense(output_dim = 6 , init = 'uniform' , activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahmudur Limon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Add output layer\n",
    "classifier.add(Dense(output_dim = 1 , init = 'uniform' , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the code\n",
    "classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the fourth GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 5s 693us/step - loss: 0.4791 - accuracy: 0.7961\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 5s 657us/step - loss: 0.4277 - accuracy: 0.7963\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 4s 567us/step - loss: 0.4226 - accuracy: 0.7976\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 4s 518us/step - loss: 0.4190 - accuracy: 0.8193\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 5s 669us/step - loss: 0.4166 - accuracy: 0.8240\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 4s 578us/step - loss: 0.4151 - accuracy: 0.8280\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 5s 646us/step - loss: 0.4137 - accuracy: 0.8304\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 5s 638us/step - loss: 0.4124 - accuracy: 0.8316\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 4s 548us/step - loss: 0.4113 - accuracy: 0.8323\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 4s 542us/step - loss: 0.4106 - accuracy: 0.8332\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 4s 547us/step - loss: 0.4102 - accuracy: 0.8320\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 4s 549us/step - loss: 0.4087 - accuracy: 0.8328\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 4s 556us/step - loss: 0.4086 - accuracy: 0.8329\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 5s 679us/step - loss: 0.4077 - accuracy: 0.8341\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 5s 652us/step - loss: 0.4072 - accuracy: 0.8331\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 4s 488us/step - loss: 0.4072 - accuracy: 0.8335\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 4s 504us/step - loss: 0.4065 - accuracy: 0.8331\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 4s 520us/step - loss: 0.4066 - accuracy: 0.8332\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 4s 506us/step - loss: 0.4063 - accuracy: 0.8361\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 4s 506us/step - loss: 0.4053 - accuracy: 0.8345\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 4s 491us/step - loss: 0.4052 - accuracy: 0.8357\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 4s 485us/step - loss: 0.4053 - accuracy: 0.8333\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 4s 509us/step - loss: 0.4050 - accuracy: 0.8336\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 4s 568us/step - loss: 0.4046 - accuracy: 0.8351\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 4s 563us/step - loss: 0.4046 - accuracy: 0.8337\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 5s 607us/step - loss: 0.4039 - accuracy: 0.8329\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 4s 493us/step - loss: 0.4017 - accuracy: 0.8359\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 4s 519us/step - loss: 0.4012 - accuracy: 0.8337\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 4s 494us/step - loss: 0.4009 - accuracy: 0.8339\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 4s 523us/step - loss: 0.4009 - accuracy: 0.8353\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 5s 627us/step - loss: 0.4006 - accuracy: 0.8352\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 5s 635us/step - loss: 0.4005 - accuracy: 0.8345\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 5s 731us/step - loss: 0.4003 - accuracy: 0.8359\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 5s 688us/step - loss: 0.4000 - accuracy: 0.8363\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 5s 617us/step - loss: 0.3996 - accuracy: 0.8359\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 4s 548us/step - loss: 0.3996 - accuracy: 0.8349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24b33863bc8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the ANN with training set\n",
    "classifier.fit(X_train , y_train , batch_size = 10 , epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the result\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\"\n",
    "\n",
    "\n",
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0 , 0, 600 , 1 , 40 , 3 , 60000 , 2 , 1 , 1 , 50000]])))\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = accuracy_score(y_test , y_pred)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1934,   57],\n",
       "       [ 335,  174]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test , y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
