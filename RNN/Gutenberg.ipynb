{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM , Dense , Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.python.keras.optimizers import TFOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the text file\n",
    "\n",
    "filename = 'wonder.txt'\n",
    "raw_txt = open(filename , 'r' , encoding = 'utf-8').read()\n",
    "raw_txt = raw_txt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " \"'\": 6,\n",
       " '(': 7,\n",
       " ')': 8,\n",
       " '*': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '/': 13,\n",
       " '0': 14,\n",
       " '1': 15,\n",
       " '2': 16,\n",
       " '3': 17,\n",
       " '4': 18,\n",
       " '5': 19,\n",
       " '6': 20,\n",
       " '7': 21,\n",
       " '8': 22,\n",
       " '9': 23,\n",
       " ':': 24,\n",
       " ';': 25,\n",
       " '?': 26,\n",
       " '@': 27,\n",
       " '[': 28,\n",
       " ']': 29,\n",
       " '_': 30,\n",
       " 'a': 31,\n",
       " 'b': 32,\n",
       " 'c': 33,\n",
       " 'd': 34,\n",
       " 'e': 35,\n",
       " 'f': 36,\n",
       " 'g': 37,\n",
       " 'h': 38,\n",
       " 'i': 39,\n",
       " 'j': 40,\n",
       " 'k': 41,\n",
       " 'l': 42,\n",
       " 'm': 43,\n",
       " 'n': 44,\n",
       " 'o': 45,\n",
       " 'p': 46,\n",
       " 'q': 47,\n",
       " 'r': 48,\n",
       " 's': 49,\n",
       " 't': 50,\n",
       " 'u': 51,\n",
       " 'v': 52,\n",
       " 'w': 53,\n",
       " 'x': 54,\n",
       " 'y': 55,\n",
       " 'z': 56}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapping of unique chars to integers\n",
    "\n",
    "chars = sorted(list(set(raw_txt)))\n",
    "chars_to_int = dict((c , i) for i , c in enumerate(chars))\n",
    "chars_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of characters:  163170\n",
      "No of vocabulary:  57\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_txt)\n",
    "n_vocab = len(chars)\n",
    "print(\"No of characters: \" , n_chars)\n",
    "print(\"No of vocabulary: \" , n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163070\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset into train and test\n",
    "\n",
    "datax = []\n",
    "datay = []\n",
    "seg_length = 100\n",
    "\n",
    "for i in range(0 , n_chars - seg_length , 1):\n",
    "    seg_in = raw_txt[i : i + seg_length]\n",
    "    seg_out = raw_txt[i + seg_length]\n",
    "    \n",
    "    datax.append([chars_to_int [char] for char in seg_in])\n",
    "    datay.append(chars_to_int[seg_out])\n",
    "    \n",
    "n_patterns = len(datax)\n",
    "print(n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31],\n",
       "        [42],\n",
       "        [39],\n",
       "        ...,\n",
       "        [12],\n",
       "        [ 1],\n",
       "        [34]],\n",
       "\n",
       "       [[42],\n",
       "        [39],\n",
       "        [33],\n",
       "        ...,\n",
       "        [ 1],\n",
       "        [34],\n",
       "        [45]],\n",
       "\n",
       "       [[39],\n",
       "        [33],\n",
       "        [35],\n",
       "        ...,\n",
       "        [34],\n",
       "        [45],\n",
       "        [53]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[44],\n",
       "        [34],\n",
       "        [31],\n",
       "        ...,\n",
       "        [ 1],\n",
       "        [31],\n",
       "        [32]],\n",
       "\n",
       "       [[34],\n",
       "        [31],\n",
       "        [50],\n",
       "        ...,\n",
       "        [31],\n",
       "        [32],\n",
       "        [45]],\n",
       "\n",
       "       [[31],\n",
       "        [50],\n",
       "        [39],\n",
       "        ...,\n",
       "        [32],\n",
       "        [45],\n",
       "        [51]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.reshape(datax , (n_patterns , seg_length , 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.54385965],\n",
       "        [0.73684211],\n",
       "        [0.68421053],\n",
       "        ...,\n",
       "        [0.21052632],\n",
       "        [0.01754386],\n",
       "        [0.59649123]],\n",
       "\n",
       "       [[0.73684211],\n",
       "        [0.68421053],\n",
       "        [0.57894737],\n",
       "        ...,\n",
       "        [0.01754386],\n",
       "        [0.59649123],\n",
       "        [0.78947368]],\n",
       "\n",
       "       [[0.68421053],\n",
       "        [0.57894737],\n",
       "        [0.61403509],\n",
       "        ...,\n",
       "        [0.59649123],\n",
       "        [0.78947368],\n",
       "        [0.92982456]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.77192982],\n",
       "        [0.59649123],\n",
       "        [0.54385965],\n",
       "        ...,\n",
       "        [0.01754386],\n",
       "        [0.54385965],\n",
       "        [0.56140351]],\n",
       "\n",
       "       [[0.59649123],\n",
       "        [0.54385965],\n",
       "        [0.87719298],\n",
       "        ...,\n",
       "        [0.54385965],\n",
       "        [0.56140351],\n",
       "        [0.78947368]],\n",
       "\n",
       "       [[0.54385965],\n",
       "        [0.87719298],\n",
       "        [0.68421053],\n",
       "        ...,\n",
       "        [0.56140351],\n",
       "        [0.78947368],\n",
       "        [0.89473684]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x / float(n_vocab)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(datay)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163070/163070 [==============================] - 519s 3ms/step - loss: 3.0074\n",
      "Epoch 2/10\n",
      "163070/163070 [==============================] - 810s 5ms/step - loss: 2.8850\n",
      "Epoch 3/10\n",
      "163070/163070 [==============================] - 519s 3ms/step - loss: 2.8334\n",
      "Epoch 4/10\n",
      "163070/163070 [==============================] - 857s 5ms/step - loss: 2.7952\n",
      "Epoch 5/10\n",
      "163070/163070 [==============================] - 972s 6ms/step - loss: 2.7635\n",
      "Epoch 6/10\n",
      "163070/163070 [==============================] - 880s 5ms/step - loss: 2.7322\n",
      "Epoch 7/10\n",
      "163070/163070 [==============================] - 916s 6ms/step - loss: 2.7003\n",
      "Epoch 8/10\n",
      "163070/163070 [==============================] - 746s 5ms/step - loss: 2.6713\n",
      "Epoch 9/10\n",
      "163070/163070 [==============================] - 686s 4ms/step - loss: 2.6444\n",
      "Epoch 10/10\n",
      "163070/163070 [==============================] - 787s 5ms/step - loss: 2.6218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d76f6eda08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x , y , epochs = 10 , batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "\n",
    "filename = \"weights-improvement-01-3.0620.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i , c) for i , c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed\n",
      "\" g at the hatter,\n",
      "who turned pale and fidgeted.\n",
      "\n",
      "'give your evidence,' said the king; 'and don't be n \"\n"
     ]
    }
   ],
   "source": [
    "# pick random seed\n",
    "\n",
    "start = np.random.randint(0 , len(datax) - 1)\n",
    "pattern = datax[start]\n",
    "print(\"Seed\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                          "
     ]
    }
   ],
   "source": [
    "# generate Characters\n",
    "\n",
    "import sys\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern , (1 , len(pattern) , 1))\n",
    "    x = x / float(n_vocab)\n",
    "    \n",
    "    prediction = model.predict(x , verbose = 0)\n",
    "    \n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    \n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1 : len(pattern)]\n",
    "\n",
    "    \n",
    "print(\"\\nDONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
